m = sum(exp(c(1,2,3))*invar_dist) # Theoretical Mean
TMean = rep(m,iter/n -1)     #Vector of all values equal to theoretical mean
mean(exp(simulated[1:(10)]))
plot (Mean)
lines(TMean)
Mean[10000]
# Running variance (sampled every n Monte Carlo steps)
Var = seq(0,iter/n-1) #Vector to hold running variance
for (i in 1:iter/n)
{
Var[i]=var(exp(simulated[1:(i*n)]))
}
v = sum(((exp(states)-m)^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
v = sum(((exp(states)-exp(m))^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
plot(Var)
lines(TVar)
v
exp(states)
exp(states) - exp(m)
m
exp(states) - m
(exp(states) - m)^2
(exp(states) - m)^2*invar_dist
iter = 10000 #Iterations
simulated = rep(0,iter) #Vector of simulated states
#Set initial State
simulated[1] = sample(c(1,2,3),1)
simulated[1]
# Simulate States for given Iterations
for (i in 1:(iter-1))
{
simulated[i+1] = sample(x = states,size = 1, prob = PMat[simulated[i],])
}
# Relative Frequencies
freq = rep(0,3) #Vector of frequencies
#Calculate relative frequencies
for (j in 1:3)
{
freq[j] <- length(which(simulated==(j)))/iter
}
freq
# Plot of expected probability from Theoretical distribution with sample probability superimposed against Markov states
plot(states,invar_dist,xlab="state",ylab="Pr(state)", main = 'Sample Distribution (Lines) with Theoretical Distribution (circles) Superimposed') # Plot of theoretical distribution - Circles
lines(states,freq,type="h")                           # Plot of sample distribution - Lines
# Running average (sampled every n Monte Carlo steps)
n = 10 # mean increase size
Mean = seq(from = 0,to = iter/n-1) # Vector to hold running means
for (i in 1:(iter/n))
{
Mean[i] = mean(exp(simulated[1:(n*i)]))
}
m = sum(exp(c(1,2,3))*invar_dist) # Theoretical Mean
TMean = rep(m,iter/n -1)     #Vector of all values equal to theoretical mean
mean(exp(simulated[1:(10)]))
plot (Mean)
lines(TMean)
# Running variance (sampled every n Monte Carlo steps)
Var = seq(0,iter/n-1) #Vector to hold running variance
for (i in 1:iter/n)
{
Var[i]=var(simulated[1:(i*n)])
}
v = sum(((states-m)^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
lines(TVar)
plot (Mean)
lines(TMean)
plot(Var)
lines(TVar)
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
lines(TVar)
# Running variance (sampled every n Monte Carlo steps)
Var = seq(0,iter/n-1) #Vector to hold running variance
for (i in 1:iter/n)
{
Var[i]=var(simulated[1:(i*n)])
}
v = sum(((states-m)^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
# Three state Phone battery life model - Low, Medium and High, represented by 0,1,2 respectively.
states = c(1,2,3)
invar_dist = c(56/155,72/155,27/155) # Theoretical Invariant distribution
# Transition Probability Matrix
PMat = rbind(c(1/10,9/10,0),c(7/10,0,3/10),c(0,8/10,2/10))
PMat
#We check convergence for powers on P from 1 to 100
invar_mat = rbind(invar_dist,invar_dist,invar_dist) # Expected Matrix to which P^N will converge
conv_check = rep(0,100) #
for (i in 1:100)
{
temp_Mat = PMat %^% i
conv_check[i] = sum(abs(temp_Mat - invar_mat)) # Abs value of difference between theoretical and actual P^N
}
plot(c(1:100), conv_check, xlab= 'N', ylab = 'Sum of Difference', main='Difference between Theroretical and Simulated Matrix of P^N')
iter = 10000 #Iterations
simulated = rep(0,iter) #Vector of simulated states
#Set initial State
simulated[1] = sample(c(1,2,3),1) #**** cHANGE
simulated[1]
# Simulate States for given Iterations
for (i in 1:(iter-1))
{
simulated[i+1] = sample(x = states,size = 1, prob = PMat[simulated[i],])
}
# Relative Frequencies
freq = rep(0,3) #Vector of frequencies
#Calculate relative frequencies
for (j in 1:3)
{
freq[j] <- length(which(simulated==(j)))/iter
}
freq
# Plot of expected probability from Theoretical distribution with sample probability superimposed against Markov states
plot(states,invar_dist,xlab="state",ylab="Pr(state)") # Plot of theoretical distribution - Circles
lines(states,freq,type="h")                           # Plot of sample distribution - Lines
# Running average (sampled every n Monte Carlo steps)
n = 10 # mean increase size
Mean = seq(from = 0,to = iter/n-1) # Vector to hold running means
for (i in 1:(iter/n))
{
Mean[i] = mean(simulated[1:(n*i)])
}
m = sum(c(1,2,3)*invar_dist) # Theoretical Mean
TMean = rep(m,iter/n -1)     #Vector of all values equal to theoretical mean
plot (Mean)
lines(TMean)
# Running variance (sampled every n Monte Carlo steps)
Var = seq(0,iter/n-1) #Vector to hold running variance
for (i in 1:iter/n)
{
Var[i]=var(simulated[1:(i*n)])
}
v = sum(((states-m)^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
# Three state Phone battery life model - Low, Medium and High, represented by 0,1,2 respectively.
states = c(1,2,3)
invar_dist = c(56/155,72/155,27/155) # Theoretical Invariant distribution
# Transition Probability Matrix
PMat = rbind(c(1/10,9/10,0),c(7/10,0,3/10),c(0,8/10,2/10))
PMat
#We check convergence for powers on P from 1 to 100
invar_mat = rbind(invar_dist,invar_dist,invar_dist) # Expected Matrix to which P^N will converge
conv_check = rep(0,100) #
for (i in 1:100)
{
temp_Mat = PMat %^% i
conv_check[i] = sum(abs(temp_Mat - invar_mat)) # Abs value of difference between theoretical and actual P^N
}
plot(c(1:100), conv_check, xlab= 'N', ylab = 'Sum of Difference', main='Difference between Theroretical and Simulated Matrix of P^N')
iter = 10000 #Iterations
simulated = rep(0,iter) #Vector of simulated states
#Set initial State
simulated[1] = sample(c(1,2,3),1) #**** cHANGE
simulated[1]
# Simulate States for given Iterations
for (i in 1:(iter-1))
{
simulated[i+1] = sample(x = states,size = 1, prob = PMat[simulated[i],])
}
# Relative Frequencies
freq = rep(0,3) #Vector of frequencies
#Calculate relative frequencies
for (j in 1:3)
{
freq[j] <- length(which(simulated==(j)))/iter
}
freq
# Plot of expected probability from Theoretical distribution with sample probability superimposed against Markov states
plot(states,invar_dist,xlab="state",ylab="Pr(state)") # Plot of theoretical distribution - Circles
lines(states,freq,type="h")                           # Plot of sample distribution - Lines
# Running average (sampled every n Monte Carlo steps)
n = 10 # mean increase size
Mean = seq(from = 0,to = iter/n-1) # Vector to hold running means
for (i in 1:(iter/n))
{
Mean[i] = mean(simulated[1:(n*i)])
}
m = sum(c(1,2,3)*invar_dist) # Theoretical Mean
TMean = rep(m,iter/n -1)     #Vector of all values equal to theoretical mean
plot (Mean)
lines(TMean)
# Running variance (sampled every n Monte Carlo steps)
Var = seq(0,iter/n-1) #Vector to hold running variance
for (i in 1:iter/n)
{
Var[i]=var(simulated[1:(i*n)])
}
v = sum(((states-m)^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
# Three state Phone battery life model - Low, Medium and High, represented by 0,1,2 respectively.
states = c(1,2,3)
invar_dist = c(56/155,72/155,27/155) # Theoretical Invariant distribution
# Transition Probability Matrix
PMat = rbind(c(1/10,9/10,0),c(7/10,0,3/10),c(0,8/10,2/10))
PMat
#We check convergence for powers on P from 1 to 100
invar_mat = rbind(invar_dist,invar_dist,invar_dist) # Expected Matrix to which P^N will converge
conv_check = rep(0,100) #
for (i in 1:100)
{
temp_Mat = PMat %^% i
conv_check[i] = sum(abs(temp_Mat - invar_mat)) # Abs value of difference between theoretical and actual P^N
}
plot(c(1:100), conv_check, xlab= 'N', ylab = 'Sum of Difference', main='Difference between Theroretical and Simulated Matrix of P^N')
iter = 10000 #Iterations
simulated = rep(0,iter) #Vector of simulated states
#Set initial State
simulated[1] = sample(c(1,2,3),1) #**** cHANGE
simulated[1]
# Simulate States for given Iterations
for (i in 1:(iter-1))
{
simulated[i+1] = sample(x = states,size = 1, prob = PMat[simulated[i],])
}
# Relative Frequencies
freq = rep(0,3) #Vector of frequencies
#Calculate relative frequencies
for (j in 1:3)
{
freq[j] <- length(which(simulated==(j)))/iter
}
freq
# Plot of expected probability from Theoretical distribution with sample probability superimposed against Markov states
plot(states,invar_dist,xlab="state",ylab="Pr(state)") # Plot of theoretical distribution - Circles
lines(states,freq,type="h")                           # Plot of sample distribution - Lines
# Running average (sampled every n Monte Carlo steps)
n = 10 # mean increase size
Mean = seq(from = 0,to = iter/n-1) # Vector to hold running means
for (i in 1:(iter/n))
{
Mean[i] = mean(simulated[1:(n*i)])
}
m = sum(c(1,2,3)*invar_dist) # Theoretical Mean
TMean = rep(m,iter/n -1)     #Vector of all values equal to theoretical mean
plot (Mean)
lines(TMean)
# Running variance (sampled every n Monte Carlo steps)
Var = seq(0,iter/n-1) #Vector to hold running variance
for (i in 1:iter/n)
{
Var[i]=var(simulated[1:(i*n)])
}
v = sum(((states-m)^2)*invar_dist) # Theoretical variance
TVar = rep(v,iter/n-1)             #Vector of all values equal to theoretical Variance
plot(Var)
lines(TVar)
plot (Mean)
lines(TMean)
m = sum(c(1,2,3)*invar_dist) # Theoretical Mean
m
v
plot (Mean, xlab = 'Sample size (x10)', main = 'Running Mean against Sample Size')
lines(TMean)
plot (Mean, xlab = 'Sample size (x10)', main = 'Running Mean against Sample Size with Theoretical Mean superimposed')
lines(TMean)
plot(Var, xlab = 'Sample size (x10)', main = 'Running Variance against Sample Size with Theoretical Variance superimposed')
lines(TVar)
### MC Random Walk with poisson distributed steps
# Function that returns vector of samples from N-Step random walk
rand_walk = function(iter , N , lam)
{
Z_vec = rep(0,iter)
for (i in 1:iter)
{
Z_vec[i] = sum(rpois(N,lam))
}
return(Z_vec)
}
library(arm)
# 5-Step Random Walk of Poisson(5) Steps
Z5_5 = rand_walk(10000,5,5) # Samples
x_1 = c(0:max(Z5_5))
y_1 = dpois(x_1,5*5) #Theoretical Distribution
discrete.histogram(Z5_5,probability='TRUE', prob.col = 'lightblue')
points(x_1,y_1,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(5) Steps
Z5_5 = rand_walk(10000,5,5) # Samples
x_1 = c(0:max(Z5_5))
y_1 = dpois(x_1,5*5) #Theoretical Distribution
discrete.histogram(Z5_5,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(5) Steps')
points(x_1,y_1,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(5) Steps
Z5_5 = rand_walk(10000,5,5) # Samples
x_1 = c(0:max(Z5_5))
y_1 = dpois(x_1,5*5) #Theoretical Distribution
discrete.histogram(Z5_5,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(5) Steps')
points(x_1,y_1,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(50) Steps
Z5_50 = rand_walk(10000,5,50) # Samples
x_2 = c(0:max(Z5_50))
y_2 = dpois(x_1,5*50) #Theoretical Distribution
discrete.histogram(Z5_50,probability='TRUE', prob.col = 'lightblue', main'5-Step Random Walk of Poisson(50) Steps')
points(x_2,y_2,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(50) Steps
Z5_50 = rand_walk(10000,5,50) # Samples
x_2 = c(0:max(Z5_50))
y_2 = dpois(x_1,5*50) #Theoretical Distribution
discrete.histogram(Z5_50,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(50) Steps')
points(x_2,y_2,col = 'black', pch = 23)
length(y_2)
length(x_2)
x_2 = c(0:max(Z5_50))
y_2 = dpois(x_2,5*50) #Theoretical Distribution
discrete.histogram(Z5_50,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(50) Steps')
points(x_2,y_2,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(50) Steps
Z5_50 = rand_walk(10000,5,50) # Samples
x_2 = c(0:max(Z5_50))
y_2 = dpois(x_2,5*50) #Theoretical Distribution
discrete.histogram(Z5_50,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(50) Steps')
points(x_2,y_2,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(500) Steps
Z5_500 = rand_walk(10000,5,500) # Samples
x_3 = c(0:max(Z5_500))
y_3 = dpois(x_3,5*500) #Theoretical Distribution
discrete.histogram(Z5_500,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(500) Steps')
points(x_3,y_3,col = 'black', pch = 23)
# 5-Step Random Walk of Poisson(500) Steps
Z5_500 = rand_walk(10000,5,500) # Samples
x_3 = c(0:max(Z5_500))
y_3 = dpois(x_3,5*500) #Theoretical Distribution
discrete.histogram(Z5_500,probability='TRUE', prob.col = 'lightblue', main='5-Step Random Walk of Poisson(500) Steps')
points(x_3,y_3,col = 'black', pch = 23)
# 100-Step Random Walk of Poisson(5) Steps
Z100_5 = rand_walk(10000,100,5) # Samples
x_4 = c(0:max(Z100_5))
y_4 = dpois(x_4,100*5) #Theoretical Distribution
U_100 = (Z100_5-500)/sqrt(500)
discrete.histogram(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
# 100-Step Random Walk of Poisson(5) Steps
Z100_5 = rand_walk(10000,100,5) # Samples
x_4 = c(0:max(Z100_5))
y_4 = dpois(x_4,100*5) #Theoretical Distribution
U_100 = (Z100_5-500)/sqrt(500)
discrete.histogram(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
hist(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
help(c)
# 100-Step Random Walk of Poisson(5) Steps
Z100_5 = rand_walk(10000,100,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_100 = (Z100_5-500)/sqrt(500)
hist(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
# 100-Step Random Walk of Poisson(5) Steps
Z100_5 = rand_walk(10000,100,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_100 = (Z100_5-500)/sqrt(500)
hist(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
# 1000-Step Random Walk of Poisson(5) Steps
Z1000_5 = rand_walk(10000,1000,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_1000 = (Z100_5-5000)/sqrt(5000)
hist(U_1000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
U_1000 = (Z1000_5-5000)/sqrt(5000)
hist(U_1000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
# 10000-Step Random Walk of Poisson(5) Steps
Z10000_5 = rand_walk(10000,10000,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_1000 = (Z1000_5-50000)/sqrt(50000) #CLT Applied to Z_1000
hist(U_10000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
# 10000-Step Random Walk of Poisson(5) Steps
Z10000_5 = rand_walk(10000,10000,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_10000 = (Z1000_5-50000)/sqrt(50000) #CLT Applied to Z_1000
hist(U_10000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
U_10000 = (Z10000_5-50000)/sqrt(50000) #CLT Applied to Z_1000
hist(U_10000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean U_100
mean(U_100)
var(U_100)
#Mean and Variance of  U_1000
mean(U_1000)
var(U_1000)
#Mean and Variance of  U_1000
mean(U_1000)
# 1000-Step Random Walk of Poisson(5) Steps
Z1000_5 = rand_walk(10000,1000,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_1000 = (Z1000_5-5000)/sqrt(5000) #CLT Applied to Z_1000
hist(U_1000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean and Variance of  U_1000
mean(U_1000)
var(U_1000)
#Mean and Variance of  U_1000
mean(U_1000)
# 10000-Step Random Walk of Poisson(5) Steps
Z10000_5 = rand_walk(10000,10000,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_10000 = (Z10000_5-50000)/sqrt(50000) #CLT Applied to Z_1000
hist(U_10000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean and Variance of  U_1000
mean(U_10000)
var(U_10000)
#Jarque-Bera Test
jarque.bera.test(U_100)
#Jarque-Bera Test
jarque.Bera.test(U_100)
library(tseries)
#Jarque-Bera Test
jarque.bera.test(U_100)
## 100-Step Random Walk of Poisson(5) Steps
Z100_5 = rand_walk(10000,100,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_100 = (Z100_5-500)/sqrt(500) #CLT Applied to Z_100
hist(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean and Variance of  U_100
mean(U_100)
var(U_100)
#Jarque-Bera Test
jarque.bera.test(U_100)
## 100-Step Random Walk of Poisson(5) Steps
Z100_5 = rand_walk(10000,100,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_100 = (Z100_5-500)/sqrt(500) #CLT Applied to Z_100
hist(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean and Variance of  U_100
mean(U_100)
var(U_100)
#Jarque-Bera Test
jarque.bera.test(U_100)
## 1000-Step Random Walk of Poisson(5) Steps
Z1000_5 = rand_walk(10000,1000,5) # Samples
nor_x = seq(-4,4,length = 1000)
nor_y= dnorm(nor_x, mean=0,sd=1) #Normal(0,1) Distribution
U_1000 = (Z1000_5-5000)/sqrt(5000) #CLT Applied to Z_1000
hist(U_1000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean and Variance of  U_1000
mean(U_1000)
var(U_1000)
#Jarque-Bera Test
jarque.bera.test(U_1000)
#Jarque-Bera Test
jarque.bera.test(U_1000)
#Jarque-Bera Test
jarque.bera.test(U_10000)
hist(U_100,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
hist(U_1000,probability='TRUE', prob.col = 'lightblue', main='100-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
hist(U_1000,probability='TRUE', prob.col = 'lightblue', main='1000-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
hist(U_10000,probability='TRUE', prob.col = 'lightblue', main='10000-Step Random Walk of Poisson(5) Steps')
lines(nor_x,nor_y,col = 'black', pch = 23)
#Mean and Variance of  U_1000
mean(U_1000)
#Mean and Variance of  U_100
mean(U_100)
var(U_100)
#Mean and Variance of  U_1000
mean(U_1000)
var(U_1000)
#Mean and Variance of  U_1000
mean(U_10000)
var(U_10000)
#Jarque-Bera Test
jarque.bera.test(U_100)
#Jarque-Bera Test
jarque.bera.test(U_1000)
#Jarque-Bera Test
jarque.bera.test(U_10000)
data = read.csv("singleSite.csv")
data = read.csv("singleSite.csv")
setwd("~/Desktop/MMathProject/MyCode")
data = read.csv("singleSite.csv")
sim_data = read.csv("simulation.csv")
class(data)
data
hist(data)
hist(data[1])
View(data)
View(data)
View(sim_data)
View(sim_data)
View(data)
View(data)
hist(data['X77'])
hist(data[['X77']])
library(arm)
discrete.histogram(data[['X77']])
