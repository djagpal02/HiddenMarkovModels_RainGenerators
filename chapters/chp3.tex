\section{History}
Andrei Markov discovered the Markov model while analyzing the relationship between consecutive letters from text in the Russian novel "Eugene Onegin". With a two state model (states Vowel and Consonant) he proved that the probabililty of letters being in a particular state are not independent. Given the current state he could probabilistically predict the next. This chain of states, with various probabilities to and from each state, formed the foundation of the Markov Chain.

\section{Markov Chain}
To define a Markov chain we must first address the Markov property.

\begin{definition}
\label{markovproperty}
	Markov Property \\
	Let \{$X_t$ ; t $\in \mathbb{N}_0$\} denote a stochastic proccess \ref{stochasticp}, where t 				represents discrete time. The process has the Markov property if and only if,
	\begin{equation}
		\prob \{X_{n+1} = i_{n+1} | X_n = i_n, X_{n-1} = i_{n-1},...,X_0 = i_0\} = \prob \{X_{n+1} = 				i_{n+1} | X_n = i_n\}
	\end{equation}
\end{definition}

\begin{definition}
\label{markovchain}
	Markov Chain \\
	A stochastic process \{$X_t$ ; t $>$ 0\} is a Markov Chain if and only if it satisfies the Markov 			property \ref{markovproperty}.
\end{definition}

To be able to use a Markov chain, we must first be able to define its transition probabilities. This becomes complex if the probabilities vary with time. Thus, we usually assume the probabilities are constant. These special Markov chains are called time-homogenous.  

\begin{definition}
\label{timehomogenous}
	Time homogenous \\
	Let \{$X_t$ ; t $\in \mathbb{N}_0$\} denote a stochastic proccess \ref{stochasticp}, where t 				represents discrete time, and $p(i,j)$ represent the transition probability from state i to state j. 
	\begin{equation}
		\prob \{X_n = j | X_{n-1} = i\} = p(i,j),       \forall n \in \mathbb{N}_0
	\end{equation}
\end{definition}

Given a time-homogenous Markov chain, we can create a 2-dimensional N x N matrix of transition probabilities, where N is the cardinality of the state space.Unique Markov chains have unique transition matrices. These matrices can be defined as below:
\begin{equation}
	P = \{ p(i,j) = \prob \{ X_n = j | X_{n-1} = i \}\}_{1 \leq i,j \leq N}
\end{equation}

\section{Applications of the Markov Model}
Markov models have many applications. To demonstrate we will present an example where the weather is represented by the states.  

\begin{example}
\label{weathermarkovchain}
	Let \{$X_t ; t \in \mathbb{N}_0$\} denote a Markov Chain, with state space S = \{rainy, sunny, 				cloudy\}, where t represents the number of days from start. Since any state can transition into any 		other state, we can say this model is ergodic. This can also be seen through fig() as each state is 		connected to all others. 
	
	\centering
    \begin{tikzpicture}
        \node[state] at(-3,0) (s) {Sunny};
        \node[state] at(3,0)  (r) {Rainy};
        \node[state] at(0,-3)  (c) {Cloudy};

        \draw
            (s) edge[bend right=20] node {} (r)
            (s) edge[bend right=20] node {} (c)
            (r) edge[bend right=20] node {} (c)
            (r) edge[bend right=20] node {} (s)
            (c) edge[bend right=20] node {} (r)
            (c) edge[bend right=20] node {} (s);
    \end{tikzpicture}
    

\end{example}

\section{Motivating the Hidden Markov Model}
These examples should show the need for adaptations to simple markov models in particular cases. 

\begin{example}
\label{}
\end{example}

Show how MM is a type of HMM.