%\label{Model_Selection}

Selecting the best model to represent a process is often not a trivial task. In this chapter we discuss methods of comparing models against data, approximating parameters and testing whether a model fits. 

\section{Maximum Likelihood Estimators}
\label{Model_Selection:Maximum_Liklihood_Estimators}

We wish to find a model that can explain a given dataset. Assume we have two such models, how do we decide which is superior at this task? In this chapter we will build on this idea. 

    \subsection{Likelihood}
    \label{Model_Selection:Maximum_Liklihood_Estimators:Likelihood}

    In this subsection we define likelihood and motivate the need for Maximum likelihood estimators.

    To decide between models we must awnser which model explains the dataset better. This can be interpreted as the probability a given model produces a sequence of observations. This probability is known as the Likelihood. We can now define this; \cite{Ross2004}.

    \begin{definition} Likelihood Function \\
        Given model $\theta$ and the observations $x_1, x_2,...,x_n$, the likelihood function is given by
        \begin{equation}
            \label{Definition:Likelihood}
            L(\theta|x_1, x_2,...,x_n) = \prob(x_1, x_2,...,x_n|\theta)
        \end{equation} 
        In other words it is given by the probability that the given model produced the given observations.
    \end{definition}

    This function allows us to directly compare which model has a higher probability of fitting the data. A model with a higher Likelihood would have a superior fit to a model with a lower likelihood. As such, it is natural to maximise the Likelihood, in search of the ideal model. 

    \subsection{Maximum Liklihood Estimators}
    \label{Model_Selection:Maximum_Liklihood_Estimators:MLE}

    Through maximizing the likelihood function \ref{Definition:Likelihood}, we can find the model that best fits the given observations. This process is called Maximum Likelihood estimation. In this subsection we will demonstrate its methodology.

    We often use log$(L(\theta|x_1, x_2,...,x_n))$ instead of $L(\theta|x_1, x_2,...,x_n)$ as this often leads to easier differenciation. This is possible as the log function is monotonically increassing thus has the same maximum at the same value of $\theta$.

    The method can be described as follows:
    \begin{enumerate}[i]
        \label{Model_Selection:Maximum_Liklihood_Estimators:MLE:Method}
        \item Calculate the joint probability density of observeriving your data $X_1 = x_1,...,X_n=x_n$ given your model $\theta$, i.e.
        \begin{equation}
            \prob(X_1 = x_1,...,X_n=x_n|\theta)
        \end{equation}
        \item Take the Natural logarithm of both sides. 
        \begin{equation}
            \ln(\prob(X_1 = x_1,...,X_n=x_n|\theta))
        \end{equation}
        \item Take the partial derivative with respect to each parameter.
        \item For each paramter, set the derivative equal to 0 and rearrange for its value. The given value will be the maximum likelihood estimation of that parameter.
    \end{enumerate}

    \begin{example}
        \label{Model_Selection:Maximum_Liklihood_Estimators:MLE:Example}
        To demonstrate \ref{Model_Selection:Maximum_Liklihood_Estimators:MLE:Method} we present the following example. 

        Let $\{1,2,4,4,4,9\}$ be our Observed data. We are convived that this data follows an expoential($\lambda$) distribution but we are unsure of what the $\lambda$ parameter is. We begin by finding the joint probability density. According to our model all observations are independent thus the joint distribution is:
        \begin{equation}
            \prob(X_1 = x_1,...,X_6=x_6|\theta) = \prob(X_1 = x_1)...\prob(X_6 = x_6)
        \end{equation}

        We can now substitute in the PDF of an expoential distribtution at the different observations.
        \begin{equation}
            \prob(X_1 = x_1,...,X_6=x_6|\theta) = \lambda e^{-\lambda} \lambda e^{-2\lambda} \lambda e^{-4\lambda} \lambda e^{-4\lambda} \lambda e^{-4\lambda} \lambda e^{-9\lambda}
        \end{equation}

        We now simplify and take the natural log of both sides.
        \begin{eqnarray}
            \ln(\prob(X_1 = x_1,...,X_6=x_6|\theta)) & = &  \ln(\lambda^6 e^{-24\lambda}) \\
            & = & ln(\lambda^6) - 24\lambda 
        \end{eqnarray}

        We now differenciate with respect to our parameter, $\lambda$.
        \begin{equation}
            \dfrac{d}{d\lambda} = \dfrac{6}{\lambda} - 24
        \end{equation}

        Finally, to find the maximum we set the differential equal to 0 and solve for $\lambda$.
        \begin{eqnarray}
            0 & = & \dfrac{6}{\lambda} - 24 \\
            24 & = & \dfrac{6}{\lambda} \\
            \lambda & = & \dfrac{6}{24} \\
            & = & \dfrac{1}{4}    
        \end{eqnarray}

        Through MLE our parameter estimate for $\lambda$ is 0.25 thus our model is expoential(0.25). Logically this seems to make sense as the expected value of this model is 4, which seems to be the most popular and central value from the dataset.
    \end{example}


    As we can see, even for a simple model the derivate is not trivial. Unfortunately in real world applications this is often the case, particurally true for Hidden Markov based models. Thus we often require alternative methods to compare models.


\section{Approximate Bayesian Computation}
\label{Model_Selection:Approximate_Bayesian_Computation}

Maximum Likelihood Estimators are not always easy to calculate. In some such cases Approximate Bayesian Computation (ABC) can provide an alternative method of parameter estimation. In this section we will discuss the principles of Bayesian Statistics, ABC and provide a demonstration.

ABC uses Bayesian inference. It involves using the prior distribution, our assumption of the model, combined with the likelihood to infer a posterior distribtution, the expected distribtution given our data and model. This can be more formally described using Bayes Theorem. Given $x$ is the data and $\theta$ is the model, 
\begin{eqnarray}
    \prob(\theta|x) & = & \dfrac{\prob(x|\theta)\prob(\theta)}{\prob(x)} \\
    \prob(\theta|x) & \propto & \prob(x|\theta)\prob(\theta) \\
    posterior  & \propto & likelihood * prior
\end{eqnarray}

ABC infers posterior distribtutions by replacing the likelihood calculatation with a comparison between observed and simulated data. \cite{Toni2009}. While there are many variations of ABC, we will focus on the simpliest, ABC Rejection Sampling. The method can be described as follows:

\begin{enumerate}
    \item Sample $\theta'$ from the prior distribution $\prob(\theta)$.
    \item Simulate dataset $x'$ using the sampled $\theta'$.
    \item Compare simulated dataset with observed dataset using a distance function. If distance is smaller than a preset $\epsilon$ then accept $\theta'$ otherwise reject. Distance  function can use summary statistics.
    \item Repeat previous steps.
\end{enumerate}

Given a small enough tolerence ($\epsilon$) and an appropriate statistic we have:
\begin{equation}
    \label{Model_Selection:Approximate_Bayesian_Computation:posterior_convergence}
    \prob_{\epsilon}(\theta|x) = \int \prob_{\epsilon}(\theta, x'|x)dx' \approx \prob(\theta|x)
\end{equation}

\begin{example}
    
\end{example}




\section{Kolmogorov-Smirnov Test}
\label{Model_Selection:Kolmogorov_Smirnov_Test}

